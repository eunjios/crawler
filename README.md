# ë¬¸ì¥ ìš”ì•½ì„ ìœ„í•œ ì›¹ í¬ë¡¤ëŸ¬
- boostcamp ai tech ìµœì¢… í”„ë¡œì íŠ¸ í•™ìŠµì„ ìœ„í•œ í…ìŠ¤íŠ¸ ë°ì´í„° í¬ë¡¤ë§
## Medium Crawler
### ğŸ‘€ How to
1. `get_links` ë‚´ë¶€ì˜ `path` ë¥¼ chromedriverì˜ ìœ„ì¹˜ë¡œ ì„¤ì • 
2. `queries`ì— í¬ë¡¤ë§ í•  ê²€ìƒ‰ì–´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
3. `to_csv(ì €ì¥ë  íŒŒì¼ëª…)` ì§€ì • 
> *[NOTE] ì•„ì§ Read More ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ. ì¶”í›„ ê°œì„ í•  ì˜ˆì •*

<br>

## ğŸš€ Troubleshooting
### âœ”ï¸ `get_links`ì—ì„œ URLì„ ì œëŒ€ë¡œ ë°›ì•„ì˜¤ì§€ ëª»í•˜ëŠ” ë¬¸ì œ 
```python
href = urllib.parse.quote(a['href'], safe=':/?&=')  # URL ì¸ì½”ë”©
full_url = "https://medium.com" + href
```
- mediumì˜ ì›¹ë¬¸ì„œë¥¼ í™•ì¸í•˜ì—¬ `aria-label="Post Preview Title"` ì˜ ì†ì„±ì„ ê°€ì§€ëŠ” `<a>`ì˜ `href` ì†ì„±ê°’ìœ¼ë¡œ ì ‘ê·¼í•¨
- í•´ë‹¹ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ. ëˆ„ë½ëœ `https://medium.com` ì„ ê¸°ì¡´ `href`ì— ì¶”ê°€í•˜ì—¬ ë§í¬ë¥¼ ì–»ìŒ 
- ì´ ê³¼ì •ì—ì„œ ì¸ì½”ë”©ì´ ì œëŒ€ë¡œ ë˜ì§€ ì•Šì•„ ì—ëŸ¬ê°€ ë°œìƒí•˜ì˜€ê³  URL ì¸ì½”ë”©ì„ í†µí•´ ì´ë¥¼ í•´ê²°í•¨.


### âœ”ï¸ `get_stories`ì—ì„œ ë³¸ë¬¸ì„ ì œëŒ€ë¡œ ë°›ì•„ì˜¤ì§€ ëª»í•˜ëŠ” ë¬¸ì œ 
```python
def get_stories(links):
    stories = []
    for index, link in enumerate(links):
        try:
            print(f'link: {link}')
            soup = get_soup(link)
            p_tags = soup.find_all('p', class_=lambda value: value and 'pw-post-body-paragraph' in value.split())
            print(p_tags)
            story = ' '.join([p.get_text(strip=True) for p in p_tags])
            print('Story:', story)
            stories.append(story)
            print(index, 'of', len(links), 'stories')
        except:
            pass
    return stories
```
- `<p>` íƒœê·¸ì˜ class ëª…ì„ ì œëŒ€ë¡œ ì§€ì •í•˜ì§€ ì•Šì•„ì„œ ë°œìƒí•œ ë¬¸ì œ
- medium ì—ì„œëŠ” ë³¸ë¬¸ í´ë˜ìŠ¤ ëª…ì´ í¬ìŠ¤íŠ¸ë§ˆë‹¤ ë‹¤ë¥´ì§€ë§Œ í´ë˜ìŠ¤ ëª…ì— `pw-post-body-paragraph` ê°€ í¬í•¨ë˜ëŠ” ê²½ìš° ë³¸ë¬¸ì— í•´ë‹¹ë¨ì„ í™•ì¸í•˜ê³  ìœ„ì™€ ê°™ì´ ì½”ë“œ ìˆ˜ì • 